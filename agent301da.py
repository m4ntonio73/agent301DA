import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_experimental.agents import create_csv_agent
from langchain.prompts import PromptTemplate
from langchain.agents.agent_types import AgentType
import pandas as pd
import os
import zipfile
import tempfile
import shutil
from dotenv import load_dotenv

st.set_page_config(
    page_title="Agent 301 DA",
    page_icon="ü§ñ"
)

# Carregar vari√°veis do arquivo .env
load_dotenv()

st.markdown('<h1 style="font-size: 2.5rem; text-align: center;">Agente Aut√¥nomo de An√°lise de Dados</h1>', unsafe_allow_html=True)
st.markdown("---")

# Bot√£o para limpar arquivos tempor√°rios
if st.button("üóëÔ∏è Limpar arquivos tempor√°rios"):
    if os.path.exists("temp_data"):
        shutil.rmtree("temp_data")
        st.success("Arquivos tempor√°rios removidos!")
    else:
        st.info("Nenhum arquivo tempor√°rio encontrado.")

st.markdown("---")

# Seletor do tipo de arquivo
file_type = st.selectbox(
    "üìÅ Tipo de arquivo:",
    ["CSV √∫nico", "ZIP com m√∫ltiplos CSVs"]
)

if file_type == "CSV √∫nico":
    uploaded_file = st.file_uploader("üì¶ Carregue um arquivo CSV", type="csv")
    
    if uploaded_file is not None:
        csv_file_path = uploaded_file.name
        
        with open(csv_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        df = pd.read_csv(csv_file_path)
        st.write("‚úÖ Arquivo CSV carregado")
        st.dataframe(df.head())
        st.write("üìä Total de registros:", len(df))

else:  # ZIP com m√∫ltiplos CSVs
    uploaded_file = st.file_uploader("üì¶ Carregue o arquivo ZIP", type="zip")
    
    if uploaded_file is not None:
        # Criar diret√≥rio de trabalho permanente
        work_dir = "temp_data"
        if not os.path.exists(work_dir):
            os.makedirs(work_dir)
        
        # Salvar o arquivo ZIP
        zip_path = os.path.join(work_dir, uploaded_file.name)
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # Extrair o arquivo ZIP
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(work_dir)
            extracted_files = zip_ref.namelist()
        
        st.write("‚úÖ Arquivo ZIP extra√≠do com sucesso!")
        st.write("üìÅ Arquivos encontrados:", extracted_files)
        
        # Procurar pelos arquivos de cabe√ßalho e itens
        cabecalho_file = None
        itens_file = None
        
        for file in extracted_files:
            file_path = os.path.join(work_dir, file)
            if 'cabecalho' in file.lower() or 'cabe√ßalho' in file.lower():
                cabecalho_file = file_path
            elif 'itens' in file.lower() or 'item' in file.lower():
                itens_file = file_path
        
        if cabecalho_file and itens_file:
            # Carregar os DataFrames
            df_cabecalho = pd.read_csv(cabecalho_file)
            df_itens = pd.read_csv(itens_file)
            
            st.write("### üìã Dados do Cabe√ßalho das Notas Fiscais")
            st.dataframe(df_cabecalho.head())
            st.write("üìä Total de notas fiscais (cabe√ßalho):", len(df_cabecalho))
            
            st.write("### üìù Dados dos Itens das Notas Fiscais")
            st.dataframe(df_itens.head())
            st.write("üìä Total de itens:", len(df_itens))
            
            # Verificar colunas comuns para mesclagem
            st.write("### üîó Preparando Mesclagem dos Dados")
            
            colunas_cabecalho = set(df_cabecalho.columns)
            colunas_itens = set(df_itens.columns)
            colunas_comuns = colunas_cabecalho.intersection(colunas_itens)
            
            st.write("üîç Colunas comuns encontradas:", list(colunas_comuns))
            
            # Tentar identificar a chave de jun√ß√£o automaticamente
            possible_keys = ['id', 'numero', 'nf', 'nota_fiscal', 'documento', 'chave']
            merge_key = None
            
            for key in possible_keys:
                matching_cols = [col for col in colunas_comuns if key.lower() in col.lower()]
                if matching_cols:
                    merge_key = matching_cols[0]
                    break
            
            if not merge_key and colunas_comuns:
                merge_key = list(colunas_comuns)[0]
            
            if merge_key:
                st.write("üîë Chave de mesclagem identificada:", merge_key)
                
                # Realizar a mesclagem
                df_merged = pd.merge(df_cabecalho, df_itens, on=merge_key, how='inner')
                
                st.write("### ‚úÖ Dados Mesclados (Cabe√ßalho + Itens)")
                st.dataframe(df_merged.head())
                st.write("üìä Total de registros mesclados:", len(df_merged))
                
                # Salvar o arquivo mesclado
                merged_file_path = os.path.join(work_dir, "notas_fiscais_mescladas.csv")
                df_merged.to_csv(merged_file_path, index=False)
                csv_file_path = merged_file_path
                df = df_merged
                
            else:
                st.error("‚ùå N√£o foi poss√≠vel identificar uma chave comum para mesclagem.")
                st.write("üí° Colunas do Cabe√ßalho:", list(df_cabecalho.columns))
                st.write("üí° Colunas dos Itens:", list(df_itens.columns))
                st.stop()
                
        else:
            st.error("‚ùå N√£o foram encontrados os arquivos de cabe√ßalho e itens esperados.")
            st.write("üí° Arquivos encontrados:", extracted_files)
            st.stop()

# Se chegou at√© aqui, temos os dados prontos para an√°lise
if uploaded_file is not None and 'df' in locals():
    
    # Fun√ß√£o para validar e corrigir queries do agente
    def enhance_query_for_full_dataset(original_query, df_info):
        """Adiciona valida√ß√µes autom√°ticas para garantir uso do dataset completo"""
        
        enhanced_query = f"""
IMPORTANTE: Voc√™ est√° analisando um dataset com {df_info['total_rows']} registros e {df_info['total_cols']} colunas.

REGRAS OBRIGAT√ìRIAS:
1. SEMPRE use df.shape[0] para confirmar o n√∫mero total de registros
2. NUNCA use apenas .head() para c√°lculos - use o dataset completo
3. Para c√°lculos (soma, m√©dia, contagem), SEMPRE use todo o dataframe


Pergunta original: {original_query}

ANTES de responder, execute este c√≥digo de valida√ß√£o:
```python
print(f"Total de registros no dataset: {{df.shape[0]}}")
print(f"Total de colunas: {{df.shape[1]}}")
```

Agora responda a pergunta considerando TODOS os {df_info['total_rows']} registros.
"""
        return enhanced_query

    # Template personalizado em portugu√™s com instru√ß√µes espec√≠ficas para notas fiscais
    if file_type == "ZIP com m√∫ltiplos CSVs (Notas Fiscais)":
        template = """
Voc√™ √© um assistente especializado em an√°lise de dados de notas fiscais que sempre responde em portugu√™s brasileiro.

REGRAS CR√çTICAS - SIGA RIGOROSAMENTE:
1. SEMPRE execute df.shape[0] primeiro para saber o total de registros
2. NUNCA use .head() para c√°lculos - apenas para visualiza√ß√£o
3. Para qualquer c√°lculo (soma, m√©dia, contagem), use o dataset COMPLETO
4. Se a pergunta pede totais, some TODAS as linhas, n√£o apenas uma amostra

Contexto dos dados:
- Dados mesclados de notas fiscais (cabe√ßalho + itens)
- Cada linha representa um item de uma nota fiscal
- Para an√°lises corretas, considere TODOS os registros

FORMATO OBRIGAT√ìRIO para c√°lculos:
1. Primeiro: df.shape para verificar tamanho
2. Depois: c√°lculo completo no dataset
3. Informar na resposta: "Analisados X registros de Y total"

Voc√™ tem acesso √†s seguintes ferramentas: {tools}

Use o seguinte formato:

Pergunta: {input}
Pensamento: Vou primeiro verificar o tamanho do dataset com df.shape, depois fazer a an√°lise completa
A√ß√£o: python_repl_ast
Entrada da A√ß√£o: df.shape
Observa√ß√£o: [resultado do shape]
Pensamento: Agora vou fazer o c√°lculo considerando TODOS os registros
A√ß√£o: python_repl_ast  
Entrada da A√ß√£o: [c√≥digo para an√°lise completa]
Observa√ß√£o: [resultado]
Pensamento: Tenho o resultado baseado em TODO o dataset
Resposta Final: [resposta em portugu√™s]

{agent_scratchpad}"""
    else:
        template = """
Voc√™ √© um assistente especializado em an√°lise de dados que sempre responde em portugu√™s brasileiro.

REGRAS CR√çTICAS - SIGA RIGOROSAMENTE:
1. SEMPRE execute df.shape[0] primeiro para saber o total de registros
2. NUNCA use .head() para c√°lculos - apenas para visualiza√ß√£o
3. Para qualquer c√°lculo (soma, m√©dia, contagem), use o dataset COMPLETO
4. Se a pergunta pede totais, some TODAS as linhas, n√£o apenas uma amostra

FORMATO OBRIGAT√ìRIO para c√°lculos:
1. Primeiro: df.shape para verificar tamanho
2. Depois: c√°lculo completo no dataset
3. Informar na resposta: "Analisados X registros de Y total"

Voc√™ tem acesso √†s seguintes ferramentas: {tools}

Use o seguinte formato:

Pergunta: {input}
Pensamento: Vou primeiro verificar o tamanho do dataset com df.shape, depois fazer a an√°lise completa
A√ß√£o: python_repl_ast
Entrada da A√ß√£o: df.shape
Observa√ß√£o: [resultado do shape]
Pensamento: Agora vou fazer o c√°lculo considerando TODOS os registros
A√ß√£o: python_repl_ast
Entrada da A√ß√£o: [c√≥digo para an√°lise completa]
Observa√ß√£o: [resultado]
Pensamento: Tenho o resultado baseado em TODO o dataset
Resposta Final: [resposta em portugu√™s]

{agent_scratchpad}"""

    # Criar o prompt personalizado
    prompt = PromptTemplate.from_template(template)

    # Verificar se a API key existe no ambiente
    google_api_key = os.getenv('GOOGLE_API_KEY')
    
    if not google_api_key:
        st.error("‚ùå API Key do Google n√£o encontrada! Verifique se o arquivo .env est√° configurado corretamente.")
        st.stop()

    # Criar o agente com prompt personalizado usando a API key do .env
    try:
        agent = create_csv_agent(
            ChatGoogleGenerativeAI(
                model="gemini-1.5-flash-latest", 
                temperature=0.3,
                google_api_key=google_api_key
            ),
            csv_file_path,
            verbose=True,
            allow_dangerous_code=True,
            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            prompt=prompt
        )

        # Form para controlar quando executar a an√°lise
        with st.form("analysis_form", clear_on_submit=False):
            
            query = st.text_input("üëâ Pergunte alguma coisa sobre os dados:")
            
            # Bot√£o centralizado e estilizado
            col1, col2, col3 = st.columns([3, 2, 3])
            with col2:
                submitted = st.form_submit_button("üîç Analisar Dados", use_container_width=True)

        # S√≥ executa quando o bot√£o for clicado E houver uma query
        if submitted:
          if not query or not query.strip():  # Verifica se est√° vazio ou s√≥ tem espa√ßos
                st.error("‚ö†Ô∏è Por favor, pergunte alguma coisa antes!")
        else:
          if submitted and query:
            # Fun√ß√£o para detectar se a pergunta √© sobre os dados ou conversa casual
            def is_data_related_query(query_text):
                # Palavras-chave que indicam perguntas sobre dados
                data_keywords = [
                    'dados', 'dataframe', 'df', 'csv', 'tabela', 'coluna', 'linha', 'registro',
                    'valor', 'quantidade', 'total', 'soma', 'm√©dia', 'm√°ximo', 'm√≠nimo',
                    'an√°lise', 'estat√≠stica', 'gr√°fico', 'resumo', 'filtrar', 'agrupar',
                    'nota fiscal', 'nf', 'item', 'fornecedor', 'produto', 'pre√ßo',
                    'qual', 'quanto', 'quantos', 'como', 'onde', 'quando', 'mostre',
                    'liste', 'calcule', 'some', 'conte', 'agrupe'
                ]
                
                # Sauda√ß√µes e conversas casuais
                casual_keywords = [
                    'oi', 'ol√°', 'ola', 'bom dia', 'boa tarde', 'boa noite',
                    'como vai', 'tudo bem', 'tchau', 'obrigado', 'obrigada',
                    'valeu', 'legal', 'bacana', 'show'
                ]
                
                query_lower = query_text.lower()
                
                # Se cont√©m palavras casuais e n√£o cont√©m palavras de dados
                has_casual = any(keyword in query_lower for keyword in casual_keywords)
                has_data = any(keyword in query_lower for keyword in data_keywords)
                
                # Se √© s√≥ sauda√ß√£o/conversa casual
                if has_casual and not has_data:
                    return False
                
                # Se n√£o tem palavras de dados e √© muito curta (prov√°vel conversa casual)
                if not has_data and len(query_text.split()) < 3:
                    return False
                    
                return True
            
            # Verificar se a pergunta √© sobre dados
            if is_data_related_query(query):
                # Preparar informa√ß√µes do dataset para valida√ß√£o
                df_info = {
                    'total_rows': len(df),
                    'total_cols': len(df.columns)
                }
                
                # Enhancear a query com valida√ß√µes autom√°ticas
                enhanced_query = enhance_query_for_full_dataset(query, df_info)
                
                with st.spinner("üîç Analisando os dados..."):
                    response = agent.run(enhanced_query)

                st.write("üí° Resposta:")
                st.write(response)
                
            else:
                # Resposta para conversas casuais
                casual_responses = {
                    'sauda√ß√µes': [
                        "Ol√°! üëã Sou seu assistente de an√°lise de dados. Como posso ajudar voc√™ a analisar os dados hoje?",
                        "Oi! üòä Estou aqui para ajudar com a an√°lise dos seus dados. O que gostaria de descobrir?",
                        "Bom dia! ‚òÄÔ∏è Pronto para explorar os dados juntos? Fa√ßa uma pergunta sobre o dataset!"
                    ],
                    'agradecimentos': [
                        "De nada! üòä Fico feliz em ajudar com a an√°lise dos dados. Tem mais alguma pergunta sobre o dataset?",
                        "Por nada! üëç Se precisar de mais an√°lises dos dados, √© s√≥ perguntar!",
                        "Sempre √†s ordens! üöÄ Pronto para mais an√°lises de dados quando quiser!"
                    ],
                    'despedidas': [
                        "At√© logo! üëã Foi um prazer ajudar com a an√°lise dos dados!",
                        "Tchau! üòä Espero ter ajudado com as an√°lises. Volte sempre!",
                        "At√© mais! üåü Continue explorando os dados!"
                    ],
                    'padr√£o': [
                        "Sou especializado em an√°lise de dados! üìä Pergunte-me algo sobre o dataset carregado.",
                        "Estou aqui para ajudar com an√°lises de dados! üîç Que tal explorarmos o dataset juntos?",
                        "Meu foco √© an√°lise de dados! üìà Fa√ßa uma pergunta sobre os dados carregados."
                    ]
                }
                
                query_lower = query.lower()
                
                if any(word in query_lower for word in ['oi', 'ol√°', 'ola', 'bom dia', 'boa tarde', 'boa noite']):
                    import random
                    response = random.choice(casual_responses['sauda√ß√µes'])
                elif any(word in query_lower for word in ['obrigado', 'obrigada', 'valeu', 'brigado']):
                    import random
                    response = random.choice(casual_responses['agradecimentos'])
                elif any(word in query_lower for word in ['tchau', 'at√© logo', 'at√© mais', 'bye']):
                    import random
                    response = random.choice(casual_responses['despedidas'])
                else:
                    import random
                    response = random.choice(casual_responses['padr√£o'])
                
                st.write("üí¨ Resposta:")
                st.write(response)
            
    except Exception as e:
        st.error(f"‚ùå Erro ao criar o agente: {str(e)}")
        st.info("üí° Verifique se sua API key est√° correta no arquivo .env")

### CSS para fixar o rodap√©
footer = """
<style>
.custom-footer {
    position: fixed;
    bottom: 0;
    left: 0;
    width: 100%;
    background-color: #ffffff;
    color: #B5B5B5;
    text-align: center;
    padding: 10px;
    font-size: 0.9em;
    z-index: 100;
}
</style>
<div class="custom-footer">
    ü§ñ Agent 301 ‚ñ´Ô∏é An√°lise de Dados ‚ñ´Ô∏é v2.1.0
</div>
"""

st.markdown(footer, unsafe_allow_html=True)
